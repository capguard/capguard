# CapGuard Environment Configuration
# Copy this file to .env and fill in your API keys

# =============================================================================
# LLM Provider API Keys
# =============================================================================

# Groq API (recommended for fast inference)
# Get your key at: https://console.groq.com/keys
GROQ_API_KEY=your-groq-api-key-here

# OpenAI API (optional)
# OPENAI_API_KEY=sk-your-key-here

# =============================================================================
# Demo Configuration
# =============================================================================

# LLM Provider for CapGuard classifier (groq, openai, ollama)
CAPGUARD_PROVIDER=groq

# Model name (for Groq: llama-3.3-70b-versatile, mixtral-8x7b-32768)
CAPGUARD_MODEL=llama-3.3-70b-versatile

# Enable debug logging (true/false)
CAPGUARD_DEBUG=false

# Ollama configuration (if using Ollama)
# OLLAMA_BASE_URL=http://localhost:11434
